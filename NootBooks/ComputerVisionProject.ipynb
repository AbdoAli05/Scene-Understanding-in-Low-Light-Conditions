{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ComputerVisionProject.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUR0v-6SslqU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "import warnings\n",
        "import keras\n",
        "\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, GlobalAveragePooling2D, Dropout, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jzIngSRXbkLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(os.listdir())\n",
        "train_path='/content/drive/MyDrive/Fillterd/train/'\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
        "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['in', 'out'], batch_size=8, shuffle=True)\n",
        "\n",
        "test_path='/content/drive/MyDrive/Fillterd/test/' \n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
        "   .flow_from_directory(directory=test_path, target_size=(224,224), classes=['in', 'out'], batch_size=8, shuffle=False)\n"
      ],
      "metadata": {
        "id": "buTWgRiAt0Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "model_name='EfficientNetB3'\n",
        "base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\", pooling='avg') \n",
        "# Note you are always told NOT to make the base model trainable initially- that is WRONG you get better results leaving it trainable\n",
        "base_model.trainable=True\n",
        "x=base_model.output\n",
        "# \n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "# loss='binary_crossentropy' activation='sigmoid'\n",
        "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
        "x = Dense(1024, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
        "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
        "x=Dropout(rate=.3, seed=123)(x)\n",
        "x = Dense(128, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
        "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
        "x=Dropout(rate=.25, seed=123)(x)        \n",
        "output=Dense(2, activation='sigmoid')(x)\n",
        "model=Model(inputs=base_model.input, outputs=output)\n",
        "lr=.001 # start with this learning rate\n",
        "model.compile(Adamax(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy']) \n",
        "# model.compile(optimizer='adam',loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics=['accuracy'])\n",
        "\n",
        "# rlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n",
        "# estop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, verbose=1,restore_best_weights=True)\n",
        "mc = ModelCheckpoint('efNetB32.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "callbacks=[mc]\n",
        "\n",
        "epochs=10\n",
        "history2=model.fit(x=train_batches,  epochs=epochs, callbacks=callbacks,  validation_data=None,\n",
        "               validation_steps=None,  verbose=1, shuffle=True,  initial_epoch=0)\n"
      ],
      "metadata": {
        "id": "CgETVz1tsolG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test_path='/content/drive/MyDrive/Fillterd/test/' \n",
        "# test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
        "#    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['in', 'out'], batch_size=16, shuffle=False)\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "saved_model = load_model('/content/drive/MyDrive/ComputerVision/efNetB3.h5')\n",
        "\n",
        "test_loss, test_acc = saved_model.evaluate(test_batches, verbose=1)\n",
        "print('Test: %.3f' % (test_acc))\n",
        "print('Loss: %.3f' % (test_loss))"
      ],
      "metadata": {
        "id": "vwg9O7JH7n3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To Plot\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/ComputerVision/trainHistoryDict', 'wb') as file_pi:\n",
        "        pickle.dump(history2.history, file_pi)\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "saved_model = load_model('/content/drive/MyDrive/ComputerVision/efNetB3.h5')\n",
        "\n",
        "h=np.load('/content/drive/MyDrive/ComputerVision/trainHistoryDict',allow_pickle='TRUE')\n",
        "# h"
      ],
      "metadata": {
        "id": "nlH_9DrQW0Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create figure with secondary y-axis\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=h['val_loss'], name=\"test loss\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=h['loss'], name=\"train loss\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=h['val_accuracy'], name=\"test accuracy\"),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=h['accuracy'], name=\"train accuracy\"),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "# Add figure title\n",
        "fig.update_layout(\n",
        "    title_text=\"Loss/Accuracy of EfficientNetB3 Model\"\n",
        ")\n",
        "\n",
        "# Set x-axis title\n",
        "fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "# Set y-axes titles\n",
        "fig.update_yaxes(title_text=\"<b>Loss</b>\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"<b>Accuracy</b>\", secondary_y=True)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bNiFonZLXC78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(h).plot(figsize=(8,5))\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(h['accuracy'])\n",
        "# plt.plot(h['val_accuracy'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'val'], loc='upper right')\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(h['loss'])\n",
        "# plt.plot(h['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'val'], loc='upper right')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "5YUHG3LvaIF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Segmentation***"
      ],
      "metadata": {
        "id": "qB_eoGHYPVcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random \n",
        "import torch\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def getColor(id):\n",
        "  if id ==0:\n",
        "    return [0,255,255]\n",
        "  elif id ==1:\n",
        "    return [139,131,120]\n",
        "  elif id ==2:\n",
        "    return [227,207,87]\n",
        "  elif id ==3:\n",
        "    return [0,0,139]\n",
        "  elif id ==4:\n",
        "    return [139,35,35]\n",
        "  elif id ==5:\n",
        "    return [152,245,255]\n",
        "  elif id ==6:\n",
        "    return [127,255,0]\n",
        "  elif id ==7:\n",
        "    return [205,91,69]\n",
        "  elif id ==8:\n",
        "    return [0,205,205]\n",
        "  elif id ==9:\n",
        "    return [154,50,205]\n",
        "  elif id ==10:\n",
        "    return [205,16,118]\n",
        "  elif id ==11:\n",
        "    return [0,201,87]\n",
        "\n",
        "model =torch.hub.load('ultralytics/yolov5','custom',path='/content/drive/MyDrive/ACV/models/best2.pt',force_reload=True)\n",
        "\n",
        "model.conf = 0.30  # confidence threshold (0-1)\n",
        "model.iou = 0.30  # NMS IoU threshold (0-1)\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/ACV/Test/Images/')\n",
        "images = glob.glob('*')\n",
        "\n"
      ],
      "metadata": {
        "id": "lwb4gzHwO_Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for img in images:\n",
        "  e = model(img, size=640)\n",
        "\n",
        "  original_image = cv2.imread(img)\n",
        "\n",
        "  img2=cv2.cvtColor(original_image,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  HSVimg = cv2.cvtColor(img2, cv2.COLOR_RGB2HSV)\n",
        "  black = np.zeros(original_image.shape, dtype=np.uint8)\n",
        "\n",
        "  bla=[0,0,0]\n",
        "  for i in range(len(e.pandas().xyxy[0]['class'])):\n",
        "    color = getColor(class_id)\n",
        "    xmin = int(e.pandas().xyxy[0]['xmin'][i])\n",
        "    xmax = int(e.pandas().xyxy[0]['xmax'][i])\n",
        "    ymin = int(e.pandas().xyxy[0]['ymin'][i])\n",
        "    ymax = int(e.pandas().xyxy[0]['ymax'][i])\n",
        "    class_id = int(e.pandas().xyxy[0]['class'][i])\n",
        "    subimg = HSVimg[ymin:ymax,xmin:xmax]\n",
        "    vectorized = subimg.reshape((-1,3))\n",
        "    vectorized = np.float32(vectorized)\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    K = 2\n",
        "    attempts=10\n",
        "    ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
        "    # convert back to 8 bit values\n",
        "    centers = np.uint8(center)\n",
        "    res = center[label.flatten()]\n",
        "    result_image = res.reshape((subimg.shape))\n",
        "    # flatten the labels array\n",
        "    labels = label.flatten()\n",
        "\n",
        "    # disable only the cluster number 2 (turn the pixel into black)\n",
        "    masked_image = np.copy(subimg)\n",
        "    # convert to the shape of a vector of pixel values\n",
        "    masked_image = masked_image.reshape((-1, 3))\n",
        "    # color (i.e cluster) to disable\n",
        "\n",
        "    if str(e.pandas().xyxy[0]['name'][i])=='Bicycle':\n",
        "      temp = color\n",
        "      color = bla\n",
        "      bla = temp\n",
        "      # print('swap is done')\n",
        "    df = pd.DataFrame(labels)\n",
        "    if df.value_counts()[0] > df.value_counts()[1]:\n",
        "      masked_image[labels == 0] = color\n",
        "      masked_image[labels == 1] = bla\n",
        "    else:\n",
        "      masked_image[labels == 1] = color\n",
        "      masked_image[labels == 0] = bla\n",
        "    \n",
        "    bla=[0,0,0]\n",
        "\n",
        "    # convert back to original shape\n",
        "    masked_image = masked_image.reshape(subimg.shape)\n",
        "    # show the image\n",
        "\n",
        "    black[ymin:ymax,xmin:xmax] = masked_image\n",
        "    # cv2.imwrite('Severe%d.png'%(index),img)\n",
        "  cv2.imwrite('/content/drive/MyDrive/ACV/Seg/'+img,black)\n",
        "  # cv2_imshow(original_image)\n",
        "  # cv2_imshow(black)"
      ],
      "metadata": {
        "id": "CpDJSkfzO_6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}